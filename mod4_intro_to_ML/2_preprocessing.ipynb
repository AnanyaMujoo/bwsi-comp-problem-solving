{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "title-preproc-01",
      "metadata": {},
      "source": [
        "# Intro to ML: Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports-preproc-02",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import datasets\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "def-preproc-03",
      "metadata": {},
      "source": [
        "## What is Preprocessing?\n",
        "Preprocessing means **cleaning and transforming raw data** so that a model can use it effectively.\n",
        "\n",
        "Common reasons:\n",
        "- Features have **different units/scales** (e.g., dollars vs. years).\n",
        "- Some columns are **categorical** (words/labels) and need numbers.\n",
        "- Reducing **noise/dimensionality** can make models faster and sometimes more accurate."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "warmup-q-04",
      "metadata": {},
      "source": [
        "### Q: Quick Checks\n",
        "a. If one feature is in **meters** and another in **millimeters**, why might a distance-based model struggle?\n",
        "\n",
        "b. Why can’t we feed the strings `\"cat\"`, `\"dog\"`, and `\"fish\"` directly into a regression model?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "warmup-a-05",
      "metadata": {},
      "source": [
        "### A:\n",
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "scaling-06",
      "metadata": {},
      "source": [
        "## Scaling\n",
        "We change the **range** or **spread** of numeric features so that none dominates just because of units.\n",
        "\n",
        "| Method | What it does | Typical range | When to use |\n",
        "|--|--|--|--|\n",
        "| StandardScaler | Subtract mean, divide by std (z-score) | mean≈0, std≈1 | Good for distance/gradient-based models (KNN, SVM, LR, NN) |\n",
        "| MinMaxScaler | Linearly rescales to a fixed interval | usually [0,1] | Good when you need bounded features or to preserve original shape |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "scaling-q-07",
      "metadata": {},
      "source": [
        "### Q: When is scaling necessary?\n",
        "Name two model types that often benefit from feature scaling and explain why."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "scaling-a-08",
      "metadata": {},
      "source": [
        "### A:\n",
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "scaling-demo-09",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo: KNN with and without scaling\n",
        "X, y = datasets.make_classification(\n",
        "    n_samples=600, n_features=3, n_informative=2, n_redundant=0, random_state=42\n",
        ")\n",
        "X = X.copy()\n",
        "X[:, 0] = X[:, 0] * 1000  # make feature 0 huge to dominate distances\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# KNN without scaling\n",
        "knn_plain = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_plain.fit(X_train, y_train)\n",
        "acc_plain = knn_plain.score(X_test, y_test)\n",
        "print(f\"Accuracy WITHOUT scaling: {acc_plain:.3f}\")\n",
        "\n",
        "# KNN with StandardScaler\n",
        "knn_scaled = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"knn\", KNeighborsClassifier(n_neighbors=5))\n",
        "])\n",
        "knn_scaled.fit(X_train, y_train)\n",
        "acc_scaled = knn_scaled.score(X_test, y_test)\n",
        "print(f\"Accuracy WITH    scaling: {acc_scaled:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "scaling-plot-10",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visual: histogram of the large-scale feature BEFORE scaling\n",
        "plt.figure()\n",
        "plt.hist(X[:,0], bins=50)\n",
        "plt.title(\"Feature 0 BEFORE scaling\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "scaling-plot-11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visual: histogram of the large-scale feature AFTER StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "plt.figure()\n",
        "plt.hist(X_scaled[:,0], bins=50)\n",
        "plt.title(\"Feature 0 AFTER StandardScaler\")\n",
        "plt.xlabel(\"Value (z-score)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "encoding-12",
      "metadata": {},
      "source": [
        "## Encoding Categorical Variables\n",
        "We must convert categories (words/labels) into numbers—**carefully**.\n",
        "\n",
        "| Encoder | Use when | Example |\n",
        "|--|--|--|\n",
        "| OneHotEncoder | No natural order (nominal) | colors: red/green/blue |\n",
        "| OrdinalEncoder | Clear order (ordinal) | spiciness: low < medium < high |\n",
        "\n",
        "**Pitfall:** Don’t assign numbers to unordered labels (e.g., dog=1, cat=2, fish=3). Models might think `fish > cat`!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "encoding-q-13",
      "metadata": {},
      "source": [
        "### Q: Nominal or Ordinal?\n",
        "a. `shirt_size` with values `S, M, L`\n",
        "\n",
        "b. `zip_code`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "encoding-a-14",
      "metadata": {},
      "source": [
        "### A:\n",
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "encoding-demo-15",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Toy dataset for encoding\n",
        "raw = pd.DataFrame({\n",
        "    \"snack\": [\"apple\", \"banana\", \"chips\", \"carrot\", \"chips\", \"apple\"],\n",
        "    \"spiciness\": [\"low\", \"medium\", \"high\", \"low\", \"medium\", \"high\"],\n",
        "    \"price_dollars\": [1.0, 1.2, 2.5, 0.9, 2.7, 1.1],\n",
        "    \"yummy_label\": [1, 1, 0, 1, 0, 1]\n",
        "})\n",
        "raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "encoding-pipe-16",
      "metadata": {},
      "outputs": [],
      "source": [
        "# One-hot (snack) + Ordinal (spiciness) + passthrough numeric\n",
        "X = raw.drop(columns=[\"yummy_label\"]) \n",
        "y = raw[\"yummy_label\"]\n",
        "\n",
        "nominal_cols = [\"snack\"]\n",
        "ordinal_cols = [\"spiciness\"]\n",
        "ordinal_order = [[\"low\", \"medium\", \"high\"]]\n",
        "num_cols = [\"price_dollars\"]\n",
        "\n",
        "preprocess = ColumnTransformer([\n",
        "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"), nominal_cols),\n",
        "    (\"ord\", OrdinalEncoder(categories=ordinal_order), ordinal_cols),\n",
        "    (\"pass\", \"passthrough\", num_cols)\n",
        "])\n",
        "\n",
        "clf = Pipeline([\n",
        "    (\"prep\", preprocess),\n",
        "    (\"logit\", LogisticRegression(max_iter=500))\n",
        "])\n",
        "\n",
        "clf.fit(X, y)\n",
        "print(\"Training accuracy:\", clf.score(X, y))\n",
        "\n",
        "ohe = clf.named_steps[\"prep\"].named_transformers_[\"ohe\"]\n",
        "encoded_names = list(ohe.get_feature_names_out(nominal_cols)) + ordinal_cols + num_cols\n",
        "print(\"Encoded feature names:\", encoded_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pca-17",
      "metadata": {},
      "source": [
        "## Principal Component Analysis (PCA)\n",
        "PCA **compresses** many features into a smaller number of new features (principal components) that capture the most variation.\n",
        "\n",
        "Why use it?\n",
        "- Easier **visualization** in 2D/3D\n",
        "- Can speed up models\n",
        "- May reduce noise\n",
        "\n",
        "Note: Always **scale** features before PCA."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pca-q-18",
      "metadata": {},
      "source": [
        "### Q: When might losing detail (via compression) be acceptable? When might it be risky?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pca-a-19",
      "metadata": {},
      "source": [
        "### A:\n",
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pca-iris-20",
      "metadata": {},
      "outputs": [],
      "source": [
        "# PCA on the Iris dataset (2 components)\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "names = iris.target_names\n",
        "\n",
        "pipe_pca = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"pca\", PCA(n_components=2))\n",
        "])\n",
        "X_2d = pipe_pca.fit_transform(X)\n",
        "expl = pipe_pca.named_steps[\"pca\"].explained_variance_ratio_\n",
        "print(\"Explained variance ratio:\", expl)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "for label in np.unique(y):\n",
        "    mask = y == label\n",
        "    plt.scatter(X_2d[mask, 0], X_2d[mask, 1], label=names[label])\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.title(\"Iris in 2D via PCA\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pca-compare-21",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare accuracy with and without PCA\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "base = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"logit\", LogisticRegression(max_iter=1000))\n",
        "])\n",
        "base.fit(X_train, y_train)\n",
        "acc_base = base.score(X_test, y_test)\n",
        "\n",
        "with_pca = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"pca\", PCA(n_components=2)),\n",
        "    (\"logit\", LogisticRegression(max_iter=1000))\n",
        "])\n",
        "with_pca.fit(X_train, y_train)\n",
        "acc_pca = with_pca.score(X_test, y_test)\n",
        "\n",
        "print(f\"Accuracy without PCA: {acc_base:.3f}\")\n",
        "print(f\"Accuracy with    PCA: {acc_pca:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exercise-22",
      "metadata": {},
      "source": [
        "## Practice: Build a Clean Pipeline\n",
        "Fill in the code below to create a training/testing split, **fit transforms on train only**, and evaluate accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exercise-a-23",
      "metadata": {},
      "source": [
        "### A:\n",
        "Please uncomment and edit the skeleton as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pipeline-skeleton-24",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def build_and_eval_pipeline(df: pd.DataFrame):\n",
        "#     \"\"\"\n",
        "#     INPUT\n",
        "#       df: a DataFrame that includes numeric, categorical, and a target column 'label'\n",
        "#     RETURNS\n",
        "#       trained pipeline, accuracy on a held-out test set\n",
        "#     \"\"\"\n",
        "#     # 1) Split into X/y\n",
        "#     # X = df.drop(columns=[\"label\"]) \n",
        "#     # y = df[\"label\"]\n",
        "#     \n",
        "#     # 2) Identify column types\n",
        "#     # nominal_cols = [...]\n",
        "#     # ordinal_cols = [...]; ordinal_order = [[...]]\n",
        "#     # num_cols = [...]\n",
        "#     \n",
        "#     # 3) Preprocess\n",
        "#     # preprocess = ColumnTransformer([\n",
        "#     #     (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"), nominal_cols),\n",
        "#     #     (\"ord\", OrdinalEncoder(categories=ordinal_order), ordinal_cols),\n",
        "#     #     (\"num\", StandardScaler(), num_cols)\n",
        "#     # ])\n",
        "#     \n",
        "#     # 4) Pipeline + split\n",
        "#     # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "#     # pipe = Pipeline([(\"prep\", preprocess), (\"model\", LogisticRegression(max_iter=1000))])\n",
        "#     # pipe.fit(X_train, y_train)\n",
        "#     # acc = pipe.score(X_test, y_test)\n",
        "#     # return pipe, acc\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exit-25",
      "metadata": {},
      "source": [
        "## Exit Ticket\n",
        "1. Why do KNN and logistic regression often benefit from scaling?\n",
        "2. When is `OrdinalEncoder` preferable to `OneHotEncoder`?\n",
        "3. Name one risk of using PCA.\n",
        "4. What is **data leakage**, and how do we avoid it when scaling/encoding?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exit-a-26",
      "metadata": {},
      "source": [
        "### A:\n",
        "YOUR ANSWER HERE"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
