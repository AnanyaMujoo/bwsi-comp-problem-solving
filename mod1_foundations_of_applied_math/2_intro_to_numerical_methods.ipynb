{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Applied Mathematics: Introduction to Numerical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Numerical Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most high school math classes (e.g. algrebra, calculus) focus on analytical techniques. Consider the following quadratic:\n",
    "$$ 0 = x^2 + 4x + 3$$\n",
    "\n",
    "From algebra, we know that we can solve for the roots of this equation analytically!\n",
    "- Method 1: factor the right hand side to get $(x + 1)(x+ 3)$\n",
    "- Method 2: Use the quadratic equation which is a general solution for all quadratic roots\n",
    "\n",
    "However, some problems that fall into one or more of the following categories:\n",
    "1. No analytical solution\n",
    "2. Difficult to compute by hand (e.g. large linear systems)\n",
    "3. Open ended, not closed form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you solve for the roots of a higher degree polynomial such as $x^7 + x^5 + 2x + 3$? \n",
    "\n",
    "How would you solve a linear system with many (e.g. >> 10) equations? \n",
    "\n",
    "What about quantifying trends from real life data with minimal assumptions? \n",
    "\n",
    "These are all types of problems that benefit from numerical methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Finding Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start our exploration of these topics with root finding algorithms! Let's look at an example case.\n",
    "\n",
    "Let $f(x) = x^3 - 6x + 2$. This means that the first derivative (i.e. its rate of change) and second derivative (i.e. the \"concavity\") are as follows:\n",
    "$$f'(x) = 3x^2 - 6$$\n",
    "$$f''(x) = 6x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x**3 - 6*x + 2\n",
    "df = lambda x: 3*x**2 - 6       # first derivative\n",
    "ddf = lambda x: 6*x             # second derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-3,3)\n",
    "plt.plot(x, f(x), label=\"f(x)\")\n",
    "plt.plot(x, df(x), label=\"f'(x)\")\n",
    "plt.plot(x, ddf(x), label=\"f''(x)\")\n",
    "plt.title(\"f(x) and its derivatives vs. x\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What do you notice about where $f'(x)$ and $f''(x)$ cross zero? What is $f(x)$ doing at those points?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: I noticed that when f(x) reaches a local extrema, the derivative is at 0, and when f(x) reaches an inflection point, the second derivative is at 0. This is because when f(x) derivative reaches 0, it changes from a positive slope to a negetive slope or vice versa, meaning that that point is the most extreme point locally. When the second derivative changes from positive to negetive, the derivative changes from increasing to decreasing, so the original function changes from concave up to convave down (or vice versa for all)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytical solution\n",
    "For a general cubic function in the form\n",
    "$$f(x) = ax^3 + bx^2 + cx + d$$\n",
    "\n",
    "and its first derivative is of the form\n",
    "$$f(x) = 3ax^2 + 2bx + c$$\n",
    "\n",
    "The **inflection points** of $f(x)$ (i.e. where it changes directions) are where $f''(x) = 0$.\n",
    "\n",
    "Note: My instructor in the breakout room confirmed to me that f'(x) here needed to be replaced with f''(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: We want to solve $0 = 3ax^2 + 2bx + c$. Please solve using the quadratic equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: \n",
    "Solution:\n",
    "$$\n",
    "x = \\frac{-b \\pm \\sqrt{b^2 - 3ac}}{3a}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What are the exact inflection points for our example case if $f'(x) = 3x^2 - 6$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: The inflection point is (0,2)\n",
    "$$\n",
    "   \\begin{align*}\n",
    "f''(x) &= 6x \\\\\n",
    "6x &= 0 \\\\\n",
    "x &= 0 \\\\\n",
    "\\end{align*}\n",
    "\\text{At } x = 0, \\text{ the value of } f(0) \\text{ is } 2. \\\\\n",
    "\\text{Therefore, the inflection point is } (0, 2).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bisection Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **bisection method** is based on the following idea:\n",
    "\n",
    "Imagine I have a function $f(x)$ over some interval $[a,b]$. If there is a sign change between $f(a)$ and $f(b)$, there there must be a point that crosses zero between $a$ and $b$! We will interatively shrink this bracket until we narrow in on a numerical solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection_method(f,a,b,tol=1e-5):\n",
    "    \"\"\"\n",
    "    f: callable function handle\n",
    "    a: minimum of interval [a,b]\n",
    "    b: maximum of interval [a,b]\n",
    "    tol: how close to the real value we want our answer to be\n",
    "    \"\"\"\n",
    "    MAX_STEPS = 1000\n",
    "    eps = np.finfo(float).eps\n",
    "    \n",
    "    # initialize\n",
    "    c = (a + b)/2.\n",
    "    c_array = [ c ]\n",
    "    \n",
    "    f_a = f(a)\n",
    "    f_b = f(b)\n",
    "    f_c = f(c)\n",
    "    \n",
    "    # check that there is a sign change over the interval [a,b]\n",
    "    if np.sign(f_a) == np.sign(f_b):\n",
    "        raise ValueError(\"no bracket: f(a) and f(b) must have different signs\")\n",
    "        \n",
    "    # Loop until we reach the TOLERANCE or we take MAX_STEPS\n",
    "    for step in range(1, MAX_STEPS + 1):\n",
    "        # Check if tolerance has been met\n",
    "        if np.abs(f_c) < tol or np.abs(b - a) < eps*c:\n",
    "            break\n",
    "        \n",
    "        # update bracket values\n",
    "        if np.sign(f_a) != np.sign(f_c):\n",
    "            b = c\n",
    "            f_b = f_c\n",
    "        else:\n",
    "            a = c\n",
    "            f_a = f_c\n",
    "        c = (a + b)/2.\n",
    "        f_c = f(c)\n",
    "        c_array.append(c)\n",
    "        \n",
    "    if step == MAX_STEPS:\n",
    "        print('Maximum number of steps exceeded')\n",
    "    \n",
    "    return c, np.array(c_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our example above, let's choose the sub-interval [-1,1] to find the middle root. \n",
    "\n",
    "Note: we could change the interval to find each of the 3 roots that we see in the plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the bisection method!\n",
    "root, root_iter = bisection_method(f,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.scatter(range(len(root_iter)), root_iter)\n",
    "plt.title(\"Convergence of Bisection Method\")\n",
    "plt.ylabel(\"Root Estimate\")\n",
    "plt.xlabel(\"Iteration #\")\n",
    "plt.xticks(range(len(root_iter)))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have a method to numerically determine where a function crosses zero. Let's use this to numerically solve for the inflection points of $f(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: choose appropriate [a,b] to find the x value where f(x) is at its maximum\n",
    "Note: think carefully about what function to give `bisection_method`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrem1, extrem_iter1 = bisection_method(df, -2, -1 )             \n",
    "print(\"The MAXIMUM value of f(x) occurs when x = {}\".format(extrem1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Now choose appropriate [a,b] to find the x value where f(x) is at its minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrem1, extrem_iter1 = bisection_method(df, 1, 2 )             \n",
    "print(\"The MINIMUM value of f(x) occurs when x = {}\".format(extrem1))\n",
    "\n",
    "infl1, infl_iter1 = bisection_method(ddf, -1, 1 )             \n",
    "print(\"The INFLECTION POINT of f(x) occurs when x = {}\".format(infl1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors and Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've established some reasons for using computers to assist in certain cases, we should discuss some of the sources of error that can occur when using these methods, how we can quantify error, and some special cases to beware of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Formulas for Quantifying Error\n",
    "\n",
    "Before discussing the different sources of error, it's important to define the ways that error is measured. \n",
    "\n",
    "Given a true value of a function $f$ and an approximate solution $F$:\n",
    "\n",
    "**Absolute Error**\n",
    "$$\n",
    "    e = | f - F |\n",
    "$$\n",
    "\n",
    "**Relative Error**\n",
    "$$\n",
    "    r = \\frac{e}{|f|} = \\frac{|f - F|}{|f|}\n",
    "$$\n",
    "\n",
    "Both equations take the absolute difference of the expected/true value and the approximate/measured value, but relative error is scaled by the magnitude of the expected value in the denominator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What are the absolute and relative errors for our root finding method above? Compare the results from the bisection method to the analytical inflection points!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A:\n",
    " Note: I'm confused about this section because I think we never were asked to analyze the inflection point numerically. \n",
    "\n",
    "The bisection method gave x = 0.0 as the inflection x-value. The analytical value was 0.0. There is 0 reletive error and 0 absolute error. \n",
    "\n",
    "Note: In the case that the question was actually targeting extrema, the analytical values are sqrt(2), and -sqrt(2). The calculated values are 1.4142131805419922, -1.4142131805419922.\n",
    "The absolute error is -3.81831103e-7 for both.\n",
    "The reletive error is -2.69995362e-7 for both. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources of Error\n",
    "|Type| Description|Example|\n",
    "|--|--|--|\n",
    "|Measurement| instrument/human error when measuring an observation | A kitchen scale that's only accurate to $\\pm$ 1g|\n",
    "|Floating point| approximating numbers with finite precision| Computers have a smallest decimal value they can represent|\n",
    "|Truncation| infinite expansion approximated by a finite one | Using a Taylor's series to approximate \n",
    "\n",
    "We'll dive into floating point errors in more depth next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Systems - IEEE 754 Binary Floating Point Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Access to IEEE Numbers\n",
    "\n",
    "Let's use the `numpy` package to demonstrate explore these floating point systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single precision\n",
    "print(numpy.finfo(numpy.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double precision\n",
    "print(numpy.finfo(numpy.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = numpy.finfo(float).eps\n",
    "MAX = numpy.finfo(float).max\n",
    "print('eps = {}'.format(eps))\n",
    "print('MAX = {}'.format(MAX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why should we care about this?\n",
    "\n",
    " - Floating point arithmetic is not commutative or associative\n",
    " - Floating point errors compound, do not assume even double precision is enough!\n",
    " - Mixing precision can be  dangerous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Simple Arithmetic\n",
    " \n",
    "Simple arithmetic $\\delta < \\epsilon_{\\text{machine}}$. \n",
    "\n",
    "Compare\n",
    "\n",
    "   $$1+\\delta - 1 \\quad vs. \\quad 1 - 1 + \\delta$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = numpy.finfo(float).eps\n",
    "delta = 0.5*eps\n",
    "x = 2*delta + 1\n",
    "y = 1 + delta + delta\n",
    "print('2 * delta + 1 = {}'.format(x))\n",
    "print('1 + delta + delta = {}'.format(y))\n",
    "print( x == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more in depth information about error and floating point systems, check out [this jupyter notebook](https://github.com/mspieg/intro-numerical-methods/blob/master/04_error.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit\n",
    "Sections of this notebook are based on the work of Marc Spiegelman and Kyle Mandli. The entirety of their course repository can be found [here](https://github.com/mspieg/intro-numerical-methods/tree/master)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
